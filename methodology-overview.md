# Methodology Overview

StoryEngine is influenced by narrative research methods \([Most Significant Change](http://www.betterevaluation.org/en/plan/approach/most_significant_change), [Global Giving’s Storytelling Project](https://www.globalgiving.org/story-tools/), [CognitiveEdge’s SenseMaker](http://cognitive-edge.com/sensemaker/), and [TASCHA’s evidence narratives](http://tascha.uw.edu/collections/evidence-narratives/)\) and participatory principles. It also draws on [grounded theory](http://betterevaluation.org/evaluation-options/thematiccoding), [developmental evaluation](http://betterevaluation.org/plan/approach/developmental_evaluation), and [utilization-focused evaluation](http://www.betterevaluation.org/en/plan/approach/utilization_focused_evaluation). Our aim: to better understand what is different now \(impacts\), how change is happening, and how we might design or adapt our strategies and practices.

> “Methods can be emergent and flexible; designs can be dynamic. Contrary to the usual practice in evaluation of fixed designs that are implemented as planned, developmental evaluation designs can change as an innovation unfolds and changes.”  
>   
> _— Michael Quinn Patton, Kate McKegg, and Nan Wehipeihana \(editors\), Developmental Evaluation Exemplars: Principles in Practice, Guilford Publications, 2016, p.12._

## Giving back

StoryEngine attempts to be sensitive to and useful for participants. We are not interested in extractive research or evaluation. We also understand that an interview is an important touchpoint and opportunity for engagement. So we look for opportunities to make connections and support participants’ work.

Unless otherwise noted, all stories are shared under a [Creative Commons Attribution](https://creativecommons.org/licenses/by/4.0/)license, so that others can build on this work, including researchers who want to analyze datasets further.

## Sampling

For Mozilla, we used purposeful sampling, focusing on foundation partners, fellows, volunteers, and people and organizations in the broader Mozilla ecosystem. We actively sought out respondents from different programs, initiatives, demographic groups, and geographies. Our sampling evolved during the pilot, and included staff tip submissions, individuals submitting their own stories, and snowball sampling.

StoryEngine was also designed to analyze stories drawn from content on the open web, such as community-generated blogs, podcasts, or videos. At this stage, however, we have only analyzed a corpus composed of participant interviews.

## Six key steps

The StoryEngine methodology consists of six steps and work is designed to be an ongoing process — a loop. You’re listening and testing throughout the process, with the goal of building stronger and more systematic feedback loops with the people you serve.

**Design → Listen → Process → Share → Analyse → Act + Loop Back**

What follows is a summary of each of the six phases, each chapter ends with tools and templates to facilitate your work. That said, StoryEngine is flexible and meant to be customized, while staying true to core principles. We encourage adaptation to different uses; it has already been tailored for events and grant reporting.

## 



